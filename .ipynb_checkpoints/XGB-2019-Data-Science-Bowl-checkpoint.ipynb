{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Data Science Bowl - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\data-science-bowl-2019\\train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df.drop(columns=['accuracy_group', 'installation_id', 'type', 'event_id'])\n",
    "train_y = df['accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x = pd.get_dummies(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 865447 entries, 0 to 865446\n",
      "Data columns (total 15 columns):\n",
      "Unnamed: 0                            865447 non-null int64\n",
      "event_count                           865447 non-null int64\n",
      "event_code                            865447 non-null int64\n",
      "game_time                             865447 non-null int64\n",
      "num_correct                           865447 non-null int64\n",
      "num_incorrect                         865447 non-null int64\n",
      "accuracy                              865447 non-null float64\n",
      "title_Bird Measurer (Assessment)      865447 non-null uint8\n",
      "title_Cart Balancer (Assessment)      865447 non-null uint8\n",
      "title_Cauldron Filler (Assessment)    865447 non-null uint8\n",
      "title_Chest Sorter (Assessment)       865447 non-null uint8\n",
      "title_Mushroom Sorter (Assessment)    865447 non-null uint8\n",
      "world_CRYSTALCAVES                    865447 non-null uint8\n",
      "world_MAGMAPEAK                       865447 non-null uint8\n",
      "world_TREETOPCITY                     865447 non-null uint8\n",
      "dtypes: float64(1), int64(6), uint8(8)\n",
      "memory usage: 52.8 MB\n"
     ]
    }
   ],
   "source": [
    "enc_train_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_gpus=1,\n",
       "              n_jobs=1, nthread=None, objective='multi:softprob',\n",
       "              predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "              subsample=1, tree_method='gpu_hist', verbosity=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = xgb.XGBClassifier(tree_method='gpu_hist', \n",
    "                          predictor='gpu_predictor', \n",
    "                          n_gpus=1)\n",
    "model.fit(enc_train_x, train_y)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r'D:\\data-science-bowl-2019\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'game_session', 'timestamp', 'event_data',\n",
       "       'installation_id', 'event_count', 'event_code', 'game_time', 'title',\n",
       "       'type', 'world'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['event_code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = df_test.drop(columns=['event_id', 'game_session', 'timestamp',\n",
    "                               'event_data', 'installation_id'])\n",
    "test_x = test_x[['event_count', 'event_code', 'game_time', 'title', 'world']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_test_x = pd.get_dummies(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['Unnamed: 0', 'event_count', 'event_code', 'game_time', 'num_correct', 'num_incorrect', 'accuracy', 'title_Bird Measurer (Assessment)', 'title_Cart Balancer (Assessment)', 'title_Cauldron Filler (Assessment)', 'title_Chest Sorter (Assessment)', 'title_Mushroom Sorter (Assessment)', 'world_CRYSTALCAVES', 'world_MAGMAPEAK', 'world_TREETOPCITY'] ['event_count', 'event_code', 'game_time', 'title_12 Monkeys', 'title_Air Show', 'title_All Star Sorting', 'title_Balancing Act', 'title_Bird Measurer (Assessment)', 'title_Bottle Filler (Activity)', 'title_Bubble Bath', 'title_Bug Measurer (Activity)', 'title_Cart Balancer (Assessment)', 'title_Cauldron Filler (Assessment)', 'title_Chest Sorter (Assessment)', 'title_Chicken Balancer (Activity)', 'title_Chow Time', 'title_Costume Box', 'title_Crystal Caves - Level 1', 'title_Crystal Caves - Level 2', 'title_Crystal Caves - Level 3', 'title_Crystals Rule', 'title_Dino Dive', 'title_Dino Drink', 'title_Egg Dropper (Activity)', 'title_Fireworks (Activity)', 'title_Flower Waterer (Activity)', 'title_Happy Camel', 'title_Heavy, Heavier, Heaviest', 'title_Honey Cake', 'title_Leaf Leader', 'title_Lifting Heavy Things', 'title_Magma Peak - Level 1', 'title_Magma Peak - Level 2', 'title_Mushroom Sorter (Assessment)', 'title_Ordering Spheres', 'title_Pan Balance', \"title_Pirate's Tale\", 'title_Rulers', 'title_Sandcastle Builder (Activity)', 'title_Scrub-A-Dub', 'title_Slop Problem', 'title_Treasure Map', 'title_Tree Top City - Level 1', 'title_Tree Top City - Level 2', 'title_Tree Top City - Level 3', 'title_Watering Hole (Activity)', 'title_Welcome to Lost Lagoon!', 'world_CRYSTALCAVES', 'world_MAGMAPEAK', 'world_NONE', 'world_TREETOPCITY']\nexpected num_incorrect, num_correct, accuracy, Unnamed: 0 in input data\ntraining data did not have the following fields: title_Honey Cake, title_12 Monkeys, title_Magma Peak - Level 2, title_Scrub-A-Dub, title_Costume Box, title_Welcome to Lost Lagoon!, title_Bubble Bath, title_Magma Peak - Level 1, title_Ordering Spheres, title_Bug Measurer (Activity), title_Dino Drink, title_Treasure Map, title_Crystals Rule, title_Sandcastle Builder (Activity), title_Bottle Filler (Activity), title_Lifting Heavy Things, title_Watering Hole (Activity), title_Fireworks (Activity), title_Chicken Balancer (Activity), title_Air Show, title_All Star Sorting, title_Balancing Act, title_Crystal Caves - Level 3, title_Egg Dropper (Activity), title_Dino Dive, title_Tree Top City - Level 2, title_Rulers, title_Crystal Caves - Level 2, title_Leaf Leader, title_Chow Time, title_Flower Waterer (Activity), title_Heavy, Heavier, Heaviest, title_Happy Camel, title_Pan Balance, title_Tree Top City - Level 3, title_Crystal Caves - Level 1, title_Slop Problem, title_Tree Top City - Level 1, title_Pirate's Tale, world_NONE",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-3eaa3bc8332c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_test_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\y33-j3t\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                                                  validate_features=validate_features)\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\y33-j3t\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\y33-j3t\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1690\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['Unnamed: 0', 'event_count', 'event_code', 'game_time', 'num_correct', 'num_incorrect', 'accuracy', 'title_Bird Measurer (Assessment)', 'title_Cart Balancer (Assessment)', 'title_Cauldron Filler (Assessment)', 'title_Chest Sorter (Assessment)', 'title_Mushroom Sorter (Assessment)', 'world_CRYSTALCAVES', 'world_MAGMAPEAK', 'world_TREETOPCITY'] ['event_count', 'event_code', 'game_time', 'title_12 Monkeys', 'title_Air Show', 'title_All Star Sorting', 'title_Balancing Act', 'title_Bird Measurer (Assessment)', 'title_Bottle Filler (Activity)', 'title_Bubble Bath', 'title_Bug Measurer (Activity)', 'title_Cart Balancer (Assessment)', 'title_Cauldron Filler (Assessment)', 'title_Chest Sorter (Assessment)', 'title_Chicken Balancer (Activity)', 'title_Chow Time', 'title_Costume Box', 'title_Crystal Caves - Level 1', 'title_Crystal Caves - Level 2', 'title_Crystal Caves - Level 3', 'title_Crystals Rule', 'title_Dino Dive', 'title_Dino Drink', 'title_Egg Dropper (Activity)', 'title_Fireworks (Activity)', 'title_Flower Waterer (Activity)', 'title_Happy Camel', 'title_Heavy, Heavier, Heaviest', 'title_Honey Cake', 'title_Leaf Leader', 'title_Lifting Heavy Things', 'title_Magma Peak - Level 1', 'title_Magma Peak - Level 2', 'title_Mushroom Sorter (Assessment)', 'title_Ordering Spheres', 'title_Pan Balance', \"title_Pirate's Tale\", 'title_Rulers', 'title_Sandcastle Builder (Activity)', 'title_Scrub-A-Dub', 'title_Slop Problem', 'title_Treasure Map', 'title_Tree Top City - Level 1', 'title_Tree Top City - Level 2', 'title_Tree Top City - Level 3', 'title_Watering Hole (Activity)', 'title_Welcome to Lost Lagoon!', 'world_CRYSTALCAVES', 'world_MAGMAPEAK', 'world_NONE', 'world_TREETOPCITY']\nexpected num_incorrect, num_correct, accuracy, Unnamed: 0 in input data\ntraining data did not have the following fields: title_Honey Cake, title_12 Monkeys, title_Magma Peak - Level 2, title_Scrub-A-Dub, title_Costume Box, title_Welcome to Lost Lagoon!, title_Bubble Bath, title_Magma Peak - Level 1, title_Ordering Spheres, title_Bug Measurer (Activity), title_Dino Drink, title_Treasure Map, title_Crystals Rule, title_Sandcastle Builder (Activity), title_Bottle Filler (Activity), title_Lifting Heavy Things, title_Watering Hole (Activity), title_Fireworks (Activity), title_Chicken Balancer (Activity), title_Air Show, title_All Star Sorting, title_Balancing Act, title_Crystal Caves - Level 3, title_Egg Dropper (Activity), title_Dino Dive, title_Tree Top City - Level 2, title_Rulers, title_Crystal Caves - Level 2, title_Leaf Leader, title_Chow Time, title_Flower Waterer (Activity), title_Heavy, Heavier, Heaviest, title_Happy Camel, title_Pan Balance, title_Tree Top City - Level 3, title_Crystal Caves - Level 1, title_Slop Problem, title_Tree Top City - Level 1, title_Pirate's Tale, world_NONE"
     ]
    }
   ],
   "source": [
    "pred = model.predict(enc_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
